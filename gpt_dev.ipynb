{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Building a GPT"
      ],
      "metadata": {
        "id": "wJpXpmjEYC_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read it in to inspect it\n",
        "with open('Mahabharat.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "O6medjfRsLD9"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"length of dataset in characters: \", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xWI_VyAsN8F",
        "outputId": "71a561c1-c955-40e4-f796-ebab29c9a263"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters:  14839497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's look at the first 1000 characters\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c5V0FvqseE0",
        "outputId": "ecee1396-b817-4970-9a2b-2981e96c41f0"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Complete Mahabharata in English\n",
            "The Mahabharata\n",
            "of\n",
            "Krishna-Dwaipayana Vyasa\n",
            "\n",
            "BOOK 1\n",
            "ADI PARVA\n",
            "Translated into English Prose from the Original Sanskrit Text by Kisari Mohan Ganguli [1883-1896]\n",
            "Scanned at sacred-texts.com, 2003. Proofed at Distributed Proofing, Juliet Sutherland, Project Manager. Additional proofing\n",
            "and formatting at sacred-texts.com, by J. B. Hare.\n",
            "TRANSLATOR'S PREFACE\n",
            "The object of a translator should ever be to hold the mirror upto his author. That being so, his chief duty is to represent so far as\n",
            "practicable the manner in which his author's ideas have been expressed, retaining if possible at the sacrifice of idiom and taste\n",
            "all the peculiarities of his author's imagery and of language as well. In regard to translations from the Sanskrit, nothing is easier\n",
            "than to dish up Hindu ideas, so as to make them agreeable to English taste. But the endeavour of the present translator has been\n",
            "to give in the following pages as literal a rendering as possible of the great wo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e-Rbyr8sfM8",
        "outputId": "357fe777-5c63-4621-b7ed-df093b884c12"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\f !\"#&'(),-.0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]_`abcdefghijklmnopqrstuvwxyzâ€”\n",
            "84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(encode(\"hii there\"))\n",
        "print(decode(encode(\"hii there\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw1LKNCgwjj1",
        "outputId": "ff018e33-c51d-4226-9ea4-1aaef8d594c7"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[64, 65, 65, 2, 76, 64, 61, 74, 61]\n",
            "hii there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
        "import torch # we use PyTorch: https://pytorch.org\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJb0OXPwzvqg",
        "outputId": "c89a5c71-7fc6-47d7-a6e1-591308080be2"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([14839497]) torch.int64\n",
            "tensor([45, 64, 61,  2, 28, 71, 69, 72, 68, 61, 76, 61,  2, 38, 57, 64, 57, 58,\n",
            "        64, 57, 74, 57, 76, 57,  2, 65, 70,  2, 30, 70, 63, 68, 65, 75, 64,  0,\n",
            "        45, 64, 61,  2, 38, 57, 64, 57, 58, 64, 57, 74, 57, 76, 57,  0, 71, 62,\n",
            "         0, 36, 74, 65, 75, 64, 70, 57, 11, 29, 79, 57, 65, 72, 57, 81, 57, 70,\n",
            "        57,  2, 47, 81, 57, 75, 57,  0,  0, 27, 40, 40, 36,  2, 14,  0, 26, 29,\n",
            "        34,  2, 41, 26, 43, 47, 26,  0, 45, 74, 57, 70, 75, 68, 57, 76, 61, 60,\n",
            "         2, 65, 70, 76, 71,  2, 30, 70, 63, 68, 65, 75, 64,  2, 41, 74, 71, 75,\n",
            "        61,  2, 62, 74, 71, 69,  2, 76, 64, 61,  2, 40, 74, 65, 63, 65, 70, 57,\n",
            "        68,  2, 44, 57, 70, 75, 67, 74, 65, 76,  2, 45, 61, 80, 76,  2, 58, 81,\n",
            "         2, 36, 65, 75, 57, 74, 65,  2, 38, 71, 64, 57, 70,  2, 32, 57, 70, 63,\n",
            "        77, 68, 65,  2, 52, 14, 21, 21, 16, 11, 14, 21, 22, 19, 54,  0, 44, 59,\n",
            "        57, 70, 70, 61, 60,  2, 57, 76,  2, 75, 57, 59, 74, 61, 60, 11, 76, 61,\n",
            "        80, 76, 75, 12, 59, 71, 69, 10,  2, 15, 13, 13, 16, 12,  2, 41, 74, 71,\n",
            "        71, 62, 61, 60,  2, 57, 76,  2, 29, 65, 75, 76, 74, 65, 58, 77, 76, 61,\n",
            "        60,  2, 41, 74, 71, 71, 62, 65, 70, 63, 10,  2, 35, 77, 68, 65, 61, 76,\n",
            "         2, 44, 77, 76, 64, 61, 74, 68, 57, 70, 60, 10,  2, 41, 74, 71, 66, 61,\n",
            "        59, 76,  2, 38, 57, 70, 57, 63, 61, 74, 12,  2, 26, 60, 60, 65, 76, 65,\n",
            "        71, 70, 57, 68,  2, 72, 74, 71, 71, 62, 65, 70, 63,  0, 57, 70, 60,  2,\n",
            "        62, 71, 74, 69, 57, 76, 76, 65, 70, 63,  2, 57, 76,  2, 75, 57, 59, 74,\n",
            "        61, 60, 11, 76, 61, 80, 76, 75, 12, 59, 71, 69, 10,  2, 58, 81,  2, 35,\n",
            "        12,  2, 27, 12,  2, 33, 57, 74, 61, 12,  0, 45, 43, 26, 39, 44, 37, 26,\n",
            "        45, 40, 43,  7, 44,  2, 41, 43, 30, 31, 26, 28, 30,  0, 45, 64, 61,  2,\n",
            "        71, 58, 66, 61, 59, 76,  2, 71, 62,  2, 57,  2, 76, 74, 57, 70, 75, 68,\n",
            "        57, 76, 71, 74,  2, 75, 64, 71, 77, 68, 60,  2, 61, 78, 61, 74,  2, 58,\n",
            "        61,  2, 76, 71,  2, 64, 71, 68, 60,  2, 76, 64, 61,  2, 69, 65, 74, 74,\n",
            "        71, 74,  2, 77, 72, 76, 71,  2, 64, 65, 75,  2, 57, 77, 76, 64, 71, 74,\n",
            "        12,  2, 45, 64, 57, 76,  2, 58, 61, 65, 70, 63,  2, 75, 71, 10,  2, 64,\n",
            "        65, 75,  2, 59, 64, 65, 61, 62,  2, 60, 77, 76, 81,  2, 65, 75,  2, 76,\n",
            "        71,  2, 74, 61, 72, 74, 61, 75, 61, 70, 76,  2, 75, 71,  2, 62, 57, 74,\n",
            "         2, 57, 75,  0, 72, 74, 57, 59, 76, 65, 59, 57, 58, 68, 61,  2, 76, 64,\n",
            "        61,  2, 69, 57, 70, 70, 61, 74,  2, 65, 70,  2, 79, 64, 65, 59, 64,  2,\n",
            "        64, 65, 75,  2, 57, 77, 76, 64, 71, 74,  7, 75,  2, 65, 60, 61, 57, 75,\n",
            "         2, 64, 57, 78, 61,  2, 58, 61, 61, 70,  2, 61, 80, 72, 74, 61, 75, 75,\n",
            "        61, 60, 10,  2, 74, 61, 76, 57, 65, 70, 65, 70, 63,  2, 65, 62,  2, 72,\n",
            "        71, 75, 75, 65, 58, 68, 61,  2, 57, 76,  2, 76, 64, 61,  2, 75, 57, 59,\n",
            "        74, 65, 62, 65, 59, 61,  2, 71, 62,  2, 65, 60, 65, 71, 69,  2, 57, 70,\n",
            "        60,  2, 76, 57, 75, 76, 61,  0, 57, 68, 68,  2, 76, 64, 61,  2, 72, 61,\n",
            "        59, 77, 68, 65, 57, 74, 65, 76, 65, 61, 75,  2, 71, 62,  2, 64, 65, 75,\n",
            "         2, 57, 77, 76, 64, 71, 74,  7, 75,  2, 65, 69, 57, 63, 61, 74, 81,  2,\n",
            "        57, 70, 60,  2, 71, 62,  2, 68, 57, 70, 63, 77, 57, 63, 61,  2, 57, 75,\n",
            "         2, 79, 61, 68, 68, 12,  2, 34, 70,  2, 74, 61, 63, 57, 74, 60,  2, 76,\n",
            "        71,  2, 76, 74, 57, 70, 75, 68, 57, 76, 65, 71, 70, 75,  2, 62, 74, 71,\n",
            "        69,  2, 76, 64, 61,  2, 44, 57, 70, 75, 67, 74, 65, 76, 10,  2, 70, 71,\n",
            "        76, 64, 65, 70, 63,  2, 65, 75,  2, 61, 57, 75, 65, 61, 74,  0, 76, 64,\n",
            "        57, 70,  2, 76, 71,  2, 60, 65, 75, 64,  2, 77, 72,  2, 33, 65, 70, 60,\n",
            "        77,  2, 65, 60, 61, 57, 75, 10,  2, 75, 71,  2, 57, 75,  2, 76, 71,  2,\n",
            "        69, 57, 67, 61,  2, 76, 64, 61, 69,  2, 57, 63, 74, 61, 61, 57, 58, 68,\n",
            "        61,  2, 76, 71,  2, 30, 70, 63, 68, 65, 75, 64,  2, 76, 57, 75, 76, 61,\n",
            "        12,  2, 27, 77, 76,  2, 76, 64, 61,  2, 61, 70, 60, 61, 57, 78, 71, 77,\n",
            "        74,  2, 71, 62,  2, 76, 64, 61,  2, 72, 74, 61, 75, 61, 70, 76,  2, 76,\n",
            "        74, 57, 70, 75, 68, 57, 76, 71, 74,  2, 64, 57, 75,  2, 58, 61, 61, 70,\n",
            "         0, 76, 71,  2, 63, 65, 78, 61,  2, 65, 70,  2, 76, 64, 61,  2, 62, 71,\n",
            "        68, 68, 71, 79, 65, 70, 63,  2, 72, 57, 63, 61, 75,  2, 57, 75,  2, 68,\n",
            "        65, 76, 61, 74, 57, 68,  2, 57,  2, 74, 61, 70, 60, 61, 74, 65, 70, 63,\n",
            "         2, 57, 75,  2, 72, 71, 75, 75, 65, 58, 68, 61,  2, 71, 62,  2, 76, 64,\n",
            "        61,  2, 63, 74, 61, 57, 76,  2, 79, 71])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's now split up the data into train and validation sets\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "f_WIXqxz0lU5"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD5Bj8Y6IAD4",
        "outputId": "52f7ee73-b7c4-4e91-aaf8-668b0cf5ae6b"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([45, 64, 61,  2, 28, 71, 69, 72, 68])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HXDe8vGJCEn",
        "outputId": "d14d13f8-8ab5-4ce8-8545-5bb94faddd37"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([45]) the target: 64\n",
            "when input is tensor([45, 64]) the target: 61\n",
            "when input is tensor([45, 64, 61]) the target: 2\n",
            "when input is tensor([45, 64, 61,  2]) the target: 28\n",
            "when input is tensor([45, 64, 61,  2, 28]) the target: 71\n",
            "when input is tensor([45, 64, 61,  2, 28, 71]) the target: 69\n",
            "when input is tensor([45, 64, 61,  2, 28, 71, 69]) the target: 72\n",
            "when input is tensor([45, 64, 61,  2, 28, 71, 69, 72]) the target: 68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4 # how many independent sequences will we process in parallel?\n",
        "block_size = 8 # what is the maximum context length for predictions?\n",
        "\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3k1Czf7LuA9",
        "outputId": "6c4618fd-bd99-4d47-ac4d-10dec1fdcce3"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[61, 70, 76,  2, 70, 65, 63, 64],\n",
            "        [76,  2, 43, 57, 69, 57,  2, 79],\n",
            "        [ 2, 62, 71, 74, 76, 64,  2, 62],\n",
            "        [ 2, 76, 64, 61,  2, 59, 71, 77]])\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[70, 76,  2, 70, 65, 63, 64, 76],\n",
            "        [ 2, 43, 57, 69, 57,  2, 79, 65],\n",
            "        [62, 71, 74, 76, 64,  2, 62, 65],\n",
            "        [76, 64, 61,  2, 59, 71, 77, 74]])\n",
            "----\n",
            "when input is [61] the target: 70\n",
            "when input is [61, 70] the target: 76\n",
            "when input is [61, 70, 76] the target: 2\n",
            "when input is [61, 70, 76, 2] the target: 70\n",
            "when input is [61, 70, 76, 2, 70] the target: 65\n",
            "when input is [61, 70, 76, 2, 70, 65] the target: 63\n",
            "when input is [61, 70, 76, 2, 70, 65, 63] the target: 64\n",
            "when input is [61, 70, 76, 2, 70, 65, 63, 64] the target: 76\n",
            "when input is [76] the target: 2\n",
            "when input is [76, 2] the target: 43\n",
            "when input is [76, 2, 43] the target: 57\n",
            "when input is [76, 2, 43, 57] the target: 69\n",
            "when input is [76, 2, 43, 57, 69] the target: 57\n",
            "when input is [76, 2, 43, 57, 69, 57] the target: 2\n",
            "when input is [76, 2, 43, 57, 69, 57, 2] the target: 79\n",
            "when input is [76, 2, 43, 57, 69, 57, 2, 79] the target: 65\n",
            "when input is [2] the target: 62\n",
            "when input is [2, 62] the target: 71\n",
            "when input is [2, 62, 71] the target: 74\n",
            "when input is [2, 62, 71, 74] the target: 76\n",
            "when input is [2, 62, 71, 74, 76] the target: 64\n",
            "when input is [2, 62, 71, 74, 76, 64] the target: 2\n",
            "when input is [2, 62, 71, 74, 76, 64, 2] the target: 62\n",
            "when input is [2, 62, 71, 74, 76, 64, 2, 62] the target: 65\n",
            "when input is [2] the target: 76\n",
            "when input is [2, 76] the target: 64\n",
            "when input is [2, 76, 64] the target: 61\n",
            "when input is [2, 76, 64, 61] the target: 2\n",
            "when input is [2, 76, 64, 61, 2] the target: 59\n",
            "when input is [2, 76, 64, 61, 2, 59] the target: 71\n",
            "when input is [2, 76, 64, 61, 2, 59, 71] the target: 77\n",
            "when input is [2, 76, 64, 61, 2, 59, 71, 77] the target: 74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xb) # our input to the transformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpyyAeIzQjlO",
        "outputId": "edf090ce-fbdd-4f94-faa2-c38c650a3879"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[61, 70, 76,  2, 70, 65, 63, 64],\n",
            "        [76,  2, 43, 57, 69, 57,  2, 79],\n",
            "        [ 2, 62, 71, 74, 76, 64,  2, 62],\n",
            "        [ 2, 76, 64, 61,  2, 59, 71, 77]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nql_1ER53oCf",
        "outputId": "0a09a104-079d-46ac-ee70-58e0452891bf"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 84])\n",
            "tensor(4.9242, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\"A&\"#Cr59cIE\"b\n",
            "QHHKc\\tMMtJ\n",
            "E4NAZ0RBNKZr.DU'Z!iyQ]ERSunceD jPu[2jJd9J#eEMtZSI1 35RU\\KiylZ3__7OV5VAE`U\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "eTyJ8qAaDdiF"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "for steps in range(100): # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs4kI8YdEkQj",
        "outputId": "c2c873bf-6fa5-4a93-ca8f-cc14d3398995"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.823068618774414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcVIDWAZEtjN",
        "outputId": "4389cd90-19cd-4609-869a-e32a36e835c1"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "37K?a42#EJ2\f!\n",
            "]S:Hdn1yOa`CVQ\"\\t-\fe4yw-!GD47_c9YZ)xU\"3VQCt5â€”J\n",
            "4?Y5dhU\n",
            "z;y2uueA;rUO0mAElX]_,gWlvn`:3gW24MDhVJ!oHJvkJ8fD#P0Hcm!0RlRR'u`lNiIRka 5!'pv\n",
            "YdQB\n",
            "8zQt(H)gOqwjW]b8f(zIWzwv]eN&)w1urqwf''7U]\"DEdP&.TV!ooIQ\\Lgru2\"5\fE\n",
            "(;\n",
            "'D.pw)3B!SqwIF:XPL:MVMlFLYw-6LID4J1[z\n",
            ":k?Z4LYT7UVnCxQj\"4l_lzxDHâ€”OXMRN(.Jk'u!n8av!02\f?EgF65t48.aRXlâ€”g#?h!8jWvnEZ0Q AIWC1)gDEg)__R\f_B`CZTT:j]i;mC)vifM;KbNK37QpGyMjTfUH0nj)wq&\"v_NLJO,KMa&C6wA?q,.4\n",
            "_83rB 4V\n",
            "fvKegYsS`\"S.pwJO5ucEvqbxFnu4)w,FgSAUo I(3:Pr2a0\fnz3iEs1x2JKNmyNK9â€”?YOoqcfmV\"s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The mathematical trick in self-attention"
      ],
      "metadata": {
        "id": "XinV8nmAnmKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3, 3))\n",
        "a = a / torch.sum(a, 1, keepdim=True)\n",
        "b = torch.randint(0,10,(3,2)).float()\n",
        "c = a @ b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('--')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('--')\n",
        "print('c=')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tukiH-NbRBhA",
        "outputId": "d98690a5-794a-4dba-d691-774cd11f2673"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "--\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "--\n",
            "c=\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# consider the following toy example:\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,2 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs_E24uRE8kr",
        "outputId": "41e59c34-f670-405a-a8e1-a96d5db5a05b"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b,:t+1] # (t,C)\n",
        "        xbow[b,t] = torch.mean(xprev, 0)\n"
      ],
      "metadata": {
        "id": "86NuXX0fn7ps"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# version 2: using matrix multiply for a weighted aggregation\n",
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
        "torch.allclose(xbow, xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhdOAd6-wXkZ",
        "outputId": "0f89f82e-ddd7-4d53-9412-b79c704a50a5"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 3: use Softmax\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "xbow3 = wei @ x\n",
        "torch.allclose(xbow, xbow3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOURrfG-ysoL",
        "outputId": "2b1e2b81-e912-4e38-83f1-2915ba991217"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 4: self-attention!\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "\n",
        "# let's see a single Head perform self-attention\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "k = key(x)   # (B, T, 16)\n",
        "q = query(x) # (B, T, 16)\n",
        "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "#wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "v = value(x)\n",
        "out = wei @ v\n",
        "#out = wei @ x\n",
        "\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDarxEWIRMKq",
        "outputId": "f79a707c-615b-4492-bf34-a9806404ec61"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT1hdtzXCjgL",
        "outputId": "22e6a578-94ea-4c0b-b189-1877829c2b4b"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
              "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
              "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes:\n",
        "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
        "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
        "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
        "- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
        "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
        "- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
      ],
      "metadata": {
        "id": "M5CvobiQ0pLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = torch.randn(B,T,head_size)\n",
        "q = torch.randn(B,T,head_size)\n",
        "wei = q @ k.transpose(-2, -1) * head_size**-0.5"
      ],
      "metadata": {
        "id": "4SNbLq5z3oBw"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl6I9n9IRTSo",
        "outputId": "6bd20c4b-5e04-4837-e4ef-598cf2e47dd9"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0449)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1tQx7oeRvtc",
        "outputId": "d12c1052-c733-4ab6-9500-d63f91d83044"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0700)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLb_odHU3iKM",
        "outputId": "271c9d7f-8729-40dd-ba74-889d63df1dd9"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0918)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB82yzt44REI",
        "outputId": "14c7045b-9973-47f9-ce66-afe0839dbf25"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1) # gets too peaky, converges to one-hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpt8569BB9_f",
        "outputId": "09f2224b-591d-4310-d21f-942172a7fff7"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm1d: # (used to be BatchNorm1d)\n",
        "\n",
        "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "    self.eps = eps\n",
        "    self.gamma = torch.ones(dim)\n",
        "    self.beta = torch.zeros(dim)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # calculate the forward pass\n",
        "    xmean = x.mean(1, keepdim=True) # batch mean\n",
        "    xvar = x.var(1, keepdim=True) # batch variance\n",
        "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
        "    self.out = self.gamma * xhat + self.beta\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.gamma, self.beta]\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "module = LayerNorm1d(100)\n",
        "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\n",
        "x = module(x)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Num7sX9CKOH",
        "outputId": "1086fadf-c4f1-4694-a1a1-b9bce9b6ed89"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[:,0].mean(), x[:,0].std() # mean,std of one feature across all batch inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "633T2cmnW1uk",
        "outputId": "2bcec3d6-13aa-4819-ad9a-5007cd2f4e72"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1469), tensor(0.8803))"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN9cK9BoXCYb",
        "outputId": "54005577-8f8b-404c-a3fc-5449972689a5"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-9.5367e-09), tensor(1.0000))"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# French to English translation example:\n",
        "\n",
        "# <--------- ENCODE ------------------><--------------- DECODE ----------------->\n",
        "# les rÃ©seaux de neurones sont gÃ©niaux! <START> neural networks are awesome!<END>\n",
        "\n"
      ],
      "metadata": {
        "id": "dRJH6wM_XFfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full finished code, for reference\n",
        "\n",
        "You may want to refer directly to the git repo instead though."
      ],
      "metadata": {
        "id": "ZcvKeBXoZFOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 16 # how many independent sequences will we process in parallel?\n",
        "block_size = 32 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.0\n",
        "# ------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "with open('Mahabharat.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "# super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoelkOrFY8bN",
        "outputId": "36fb3a0c-e9b0-41a3-9de4-77a79f235dce"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.21218 M parameters\n",
            "step 0: train loss 4.6268, val loss 4.6188\n",
            "step 100: train loss 2.6066, val loss 2.6264\n",
            "step 200: train loss 2.4926, val loss 2.5111\n",
            "step 300: train loss 2.4358, val loss 2.4324\n",
            "step 400: train loss 2.3582, val loss 2.3730\n",
            "step 500: train loss 2.2769, val loss 2.2963\n",
            "step 600: train loss 2.2068, val loss 2.2292\n",
            "step 700: train loss 2.1536, val loss 2.1802\n",
            "step 800: train loss 2.1014, val loss 2.1197\n",
            "step 900: train loss 2.0650, val loss 2.0848\n",
            "step 1000: train loss 2.0144, val loss 2.0326\n",
            "step 1100: train loss 1.9842, val loss 2.0027\n",
            "step 1200: train loss 1.9501, val loss 1.9749\n",
            "step 1300: train loss 1.9291, val loss 1.9476\n",
            "step 1400: train loss 1.8868, val loss 1.9136\n",
            "step 1500: train loss 1.8704, val loss 1.8870\n",
            "step 1600: train loss 1.8433, val loss 1.8596\n",
            "step 1700: train loss 1.8258, val loss 1.8494\n",
            "step 1800: train loss 1.8037, val loss 1.8259\n",
            "step 1900: train loss 1.7876, val loss 1.8049\n",
            "step 2000: train loss 1.7752, val loss 1.7839\n",
            "step 2100: train loss 1.7470, val loss 1.7768\n",
            "step 2200: train loss 1.7526, val loss 1.7836\n",
            "step 2300: train loss 1.7375, val loss 1.7513\n",
            "step 2400: train loss 1.7236, val loss 1.7406\n",
            "step 2500: train loss 1.7055, val loss 1.7249\n",
            "step 2600: train loss 1.7014, val loss 1.7144\n",
            "step 2700: train loss 1.6861, val loss 1.7090\n",
            "step 2800: train loss 1.6662, val loss 1.7119\n",
            "step 2900: train loss 1.6710, val loss 1.6950\n",
            "step 3000: train loss 1.6540, val loss 1.6913\n",
            "step 3100: train loss 1.6427, val loss 1.6821\n",
            "step 3200: train loss 1.6471, val loss 1.6611\n",
            "step 3300: train loss 1.6376, val loss 1.6552\n",
            "step 3400: train loss 1.6357, val loss 1.6491\n",
            "step 3500: train loss 1.6302, val loss 1.6571\n",
            "step 3600: train loss 1.6303, val loss 1.6446\n",
            "step 3700: train loss 1.6051, val loss 1.6453\n",
            "step 3800: train loss 1.6137, val loss 1.6374\n",
            "step 3900: train loss 1.5988, val loss 1.6303\n",
            "step 4000: train loss 1.5819, val loss 1.6155\n",
            "step 4100: train loss 1.5838, val loss 1.6090\n",
            "step 4200: train loss 1.5900, val loss 1.6067\n",
            "step 4300: train loss 1.5830, val loss 1.6087\n",
            "step 4400: train loss 1.5728, val loss 1.5871\n",
            "step 4500: train loss 1.5660, val loss 1.5823\n",
            "step 4600: train loss 1.5670, val loss 1.5846\n",
            "step 4700: train loss 1.5624, val loss 1.5940\n",
            "step 4800: train loss 1.5550, val loss 1.5838\n",
            "step 4900: train loss 1.5531, val loss 1.5768\n",
            "step 4999: train loss 1.5504, val loss 1.5782\n",
            "\n",
            "kings, SEvice teloyely, O god ne, the moment Rimsana's alone, we a net unixinces of debore the Kanjama. The curtuous is hill to teseth tree the the Berme by endued, that foremositable. Destanst throops leapons sacrified. Even (notless into greach all also, grot not cher-other were to theire, slible Yudhishthira men Vi). Indestations,\n",
            "formerities at the highly benefore befortained with the deeds. Some with and\n",
            "the Kanma (vyikas; O though im,\n",
            "and descent should clignancious. Aght so amongsty with my nungation also the were engage or from and all these kingdoms of all\n",
            "his the emmance off my thundred any that beneting conmans the Purishna dihimpsethy dedave in car pierce and as Krityas in celestifing Everyas, become that the Pandavas. Embanning constitution of\n",
            "airanced on\n",
            "hearty (all girate to men the\n",
            "Mataidst. This Parayasas, their monase spoured of cansts, as univeth Vaisas; and addred these forbulowed by be the sorceed with aresway in in Bhima\n",
            "amonnabe beambly\n",
            "herobing with-ager of anime an spressed, as piercion, in me heeplicit of universe beast thee thing ornact thousaking, delk rampety men as two the midst of Jaya advana Parquani, le then kind8m.\n",
            "Dhalata in\n",
            "a burds destrities who towards. once the ellopinere, viz iman encounted on his as replated cark\n",
            "and Apprayenpa, They Pandu amayaWha for other unuch approwed any assived Arjuna, with O Dhouranta, prowing uponance, on\n",
            "every worng, Embering them of Parvana. Con in geach louded to\n",
            "knowed the personly, Vishmnuving, person me\n",
            "horeaded a makened with her pierparants; in their divinglor, al single on every convetrata, the moreth other succeive; having torrible.\n",
            "\"(SEging uporse competest regarding him cleapinstlents the Nauspahadra by acquied a\n",
            "deiing the trus parth, a great of imay same in behining the king, might of a greairs thee lainer of eye, in prone accome the are almertiey thou arty the celestial, and which its among heroad beholding concertated then CEars, the namen of hearw the wild natured be with eff Bright \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# generate from the model\n",
        "#context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=20000)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxM1vLrR1tEo",
        "outputId": "8da2e16c-70a7-4042-e62a-bad04f522dc2"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "from\n",
            "company victor, the are the celestice to commentanumed. And the protected, all the eld\n",
            "of Jigijita), O king. After however, O antire hopession armysy, those him sacrificial colliwed a held noth to thou elephants at Taming lone to forer poince, we the votants of Duryodhana, abdurent ingnum. And exclouding, from thou is their\n",
            "however wheeth And cosequea my men while not, and with not shafts Bhasara saying\n",
            "infin. Krunga taksa, haveous, apppen the Benal\n",
            "Prithatya feed thee high-seek of marile be keepen their chards word Dauspaded Drounting them into\n",
            "marissed in this being dimer to mementy. Thou diversant as thee from that chevereupon to the Pandava not univing any jepty, the words, plowess.\n",
            "It the fruit of counted wounding pam. He Nara is the all sup all holebjacted the bodyied on in stendanth ambapayething not for with the Jarnas arsond, with their perform their spereed to yet creanses\n",
            "of the person of Pa and Seana gorded by esire a\n",
            "palicial and hygit, soul, O fill do depation of the knowledge everything of the priginiting of consequence bodees pereated said that Satyama's men depearing assellige, the cosper-becomed insmaiveve a Ganu heroic is this bock besmength mind hath been deributfulth behof the jay of Kax done reace carding is, the heark of Jandama, a confenst' mespen one the greatt all treses time, the tigethat. Yuththing Hishing him, That giverst to poln to man. 'Sonshed imany profess, for hearm as\n",
            "exhoge were to themercely eleprated be lived stometed by this agreable etire hime. One evings, all to but thou thee ealth the pon deeprising of the life all Kelfight, is what come to sto cunded their opparice of the rearing of live a, chersavet reader, the life also of Vainum the falth, ibXeed the Karna of or Nala likpa dith roweth a deepily, teized Bhimana, of mountour also resen be tigun and Karyaja, your wheth rese in cursed not wight act to an Dhatadhana whomments and beiattionm besens, Jaryudhaka, to impen, Dishtyukya are dour all a Brahmanas. Thou art\n",
            "bult every occupors of all the manylans.\n",
            "\"Sara, seized, the plady with a mighty kild 17] cloudder among engoodiled in so he\n",
            "ruled is bhome\n",
            "chauma are to thright. The inconsigerable ofs, whadimed prectain to mighty expen that gone up, commen). I maill should Ramuseth with proudned by them are\n",
            "sometituted.' Thim recheelding him? They damong of\n",
            "Brahmanasena and Parthing, he vacturees active to the rivers, exclepain and comtan off neir expedingly proped tanson prospetinct. He looked and the Kurutha. Who should is land. The god region and hery dour obthers of the hard had their ? Myoodhu's affour in thee to diswings, O ight monarch, a)yone, the ved learn. And been the Viras, Kula of Durejediya podess and thou not the brother to him unto Pandu our sacrifya\n",
            "daughter. Nel then efforemost ship, objects, consting a thou who a is, have\n",
            "senses coting on the Kruning (Rarm.\n",
            "Me what my it herounced other thousants all these world on for then, we next, senturners from the his endued for are othiched he ower to herimens? 'I he meritual Yugavas to thee the, and great of the good affly, and the empenciblude this perboaratained the slaughteous thim is efeding him. Well head beang with desires of with grat from his consequence of\n",
            "Rama, the Sudampathana., withed with Bhima,\n",
            "with the fifiged bright, in buty him in the were that blazed so be assoon the Pandika exsoul, Parvana, head\n",
            "end, the\n",
            "king, and there\n",
            "very lord which desire, the Karuha, who he men coming any supported someth. They all the eter dreapon in tainis\n",
            "proth anck of the Brahmanas, even of Brahmanas of\n",
            "all the moby thee, the peneartingth excellent, the oSe foremosticitutionit up a mounting heads not converserying that mighty vest into that lorfumnam. Nell him of an fer to king. He (obstedied by what, courst and with Karma began him resplendued with blaods exceeded Hishis without my being this, is during fearse the earth. O glived counted an lotooked a the Freetinally, of without three kingly, had are\n",
            "kingdom the grast devoture of these foremost of Karna, the pressalt of dreven be\n",
            "whereld approudinable of a fit, In\n",
            "spay, anjoiz all notiguentath\n",
            "and Panduuga. What desirting who I manneth\n",
            "a mind, Dailas and clubs before an of the hanquirisht long up, approared giver other him. The its ditim. I said, him all 'Himany-to flueth impones. Tenched Krish, a shose seoul and operitated flar what incelessed caused, withed sacde ruler thou thus\n",
            "and the Pandu, and man the peroce occondical dutifes and\n",
            "imperershan, Salwa's soonly force this mare a firmed yeanst\n",
            "him devoteder to best these arestroyakers of the jeen of the maEbhing the scutched persotaked and graswati is hon seized of Gancharabha shake one behoved by foremong medank desies of this lakst all the Bith, claying thhat are the prived of the thee trudly Gautyarmana and Karna heid for vath the Ergered and constily! All bullsowing he self to unagoned beng\n",
            "jowered with relestial ransts (he been about appeons of I every Bhimasena vy desire of elecited the mindisV by all all anowly so. To agrees mempsed with the greass of penappance, high-see, is that achare fremost abode, all Somayhana. I prom hime cap sons, Saulama. And cartal\n",
            "companioful juchtaring a the Chenturity eleph person being bearth a peth to battle me, convery Prearishtra's sons from ho, is protecteth aniversal. O mightt the Earth) I depith we thee who in Kaluded by Adraya, O pone henore13? The living prisity, is me high-sexense when a happily, go acts unsiding regared rombection! if give, O Klavadra, all\n",
            "the Taughtera beloned steed in\n",
            "puhad and excyed, the Hutamka and in the seke with crusened by at drance thremoter all\n",
            "knowledge not this make towal themosth of the Ganga, the\n",
            "gaiming abuted the back creally Camayed their everyhishtred me in his great tostidom and hirself thee sot otherwice. A, I ha-With gen conneth Kring that is religeing him! \"Dhrishth(Bhimas greated Pancal. Buck with thin Amanna is campasures and the depeserable of the abeandenty of\n",
            "great his is respotices too king, O king, Krishna. Emendues) the king, of thou orgne these Abhava le nelighter bein coons experedhing one, that hithermants. It is the sceptured in deang. Pre Bhima when three\n",
            "agrences encessed by the peart all\n",
            "thee pereace of the king. Folk, covet ome whele them foremosthing the good bearing Himanyana, and fe en fooke to cing thou pouring his pleap\n",
            "broduct.\n",
            "This and the thing his conertains; I vay words mighty.\n",
            "Thou universerving grantived and Seauning him spremocted\n",
            "by leader clourouds we himpled the Gandharva. We bhave kinds the me, seizes leading him. O fire, and also effi their Soons Bary\n",
            "ormames) not the\n",
            "jaustion. Chichthiration every prover though this knowithing Brahmanas seity duty turn a\n",
            "bregan of their a four person of saxe with were bath maughtered he refoles. All the Virihtme, and Sateva. And the victory, the proppon\n",
            "all doubted and gane\n",
            "great impitatey of Narava like also hambs) and know himselves, the prover to\n",
            "brepely thou efleachts\n",
            "Kuruserva and gonance. Set than son, my whom\n",
            "gold with them, obtained from seen and creasere sees a lisdom bear every who hauthing welith doud coonfering of Mrathadhara, life body goldection.,\n",
            "thanse nekish\n",
            "despect line, the kings diter of espired, object helpering pregard in universes armbled with this mour commentained that sat bleon that we and a like to\n",
            "blazked with the kingdoment.['s in thee both proteed unto the obtainine. greateons had acting thee. And itso in the mery, elemong obter the king) sen\n",
            "mentation, Bhima, an the slaughter of the doth. Sind with the kingdomes diverse stacred to nother thy kinds said on his from any iretained (persomed their oppays and\n",
            "creareadon, Tell deable excepty. A\n",
            "soremong that diverse ounded abonut this\n",
            "cloak proceededered these retide of could, then chally played those beholdery Parna gold, with thee. Yandh morasuch offer up crive, victory for liken depriorh four det thee. Inta action do, the Tall with mary year, all me nounth loned pletere energy; grief by become to know anoth the Pancian and the other. Thus ime upon any presendicy, Jayanda kingss, the Apparasa as the persire) being vericected a ne king with that will bodes, thoweforemblethe worder ways engus! Ambandable, the strike that the many kine foe. And on the moon\n",
            "of prace of the ipspet for of to be munives a heroped and everything confinam with verew to words rach, one must.\"\n",
            "\"Thou said, _udam and Kupona, a and conshippinence various letender, it my eldagened to soult diverse me looud with whose persons conveting the fearing of the Likation of ordues haven conmence, a great Telegest of\n",
            "many other the, Brahmana. Abhoara said gon immongstroigh felestion and Embauil claught off mingly yeara. Thou beging in thou receled all upon texerce he this that giver one Yoga, persecis fey she among almen Kmyaka,\n",
            "number of other-son of Dala whom ealth\n",
            "prodess togance, and mosth, not the\n",
            "king over the placed othey leappince and limongly, the kings, creal of their Naishtra's Dharata?--Sauna. All thou usporticate each of the monari, and he dorning in idoriting vow de expressed with\n",
            "their Bhima while there sons mensidencted in this\n",
            "my yeth is viltate in the windst of (Karna felt reanst (knowing religers by the Dhataka in covelections, which Bhima encoul dearing lordown on minnise, and that vict arrowds, repelituance, sheyed with slooked to Kerajas, he souled destructation.' Beholding them lingssired by wheleptor the diverse of cartal and\n",
            "mooppossed my been fime, oven cleantes performies by othere Parsha, virtant in Ganda. And ifter hereap to (the benyth one said in Matra's tire. The the is Bhigh-wynished to the sperior of himstouling and vowledge,\n",
            "by haven in the diving of his not the greating with your all seen tomes. Nell, the Yendicied with I mverefore, hearipate gold, O countress. a pierceld vitues, in viertt obtained to thou king, humbsed name. Alaympayana. I is fandipa the body sconded god blazpe the penantion of Cashtha, behold of all plaons idson of Bharage uponejay, clau_tle to consequence at with a heath, himselplf ham begances herail been to undifteds withdra that plearent at those screparth [47576] By human became hlean, O maits all celestial\n",
            "suihakadeuded thee ergy-sore of soulgnt.' Brothimana, them the possessior of eveth if\n",
            "it. He Chattri sattha, my freet an father a kings. Net only herour obtal and Marata.\n",
            "Instrious is thee Uphatagement and Ambataye proceeding best-so to humones resenself in\n",
            "comminate to lincess unconty, las attruct thinishtan and Naladhu, deedy elephants and Knivas, light is the down ove to a men, should and bename that side with, sing, on, on spot the Sataking He exway acts. He all and the Punara and covetantial gereat\n",
            "also Partha and Bharathimena, jucay confermisences, grieff the ose in kmen blazing than sperienctates, in my hidsuch is\n",
            "perform mety sinlesson his chich being\n",
            "wine so grained, my Soundishmikena, do that a maists king sauch in that aire not men all runumbounded the not Vedirata, decame convery, of Bharata knowes worship's cslamen, in the O shaking, all esiding the name scrupations the words with this Yudhishthiru, and beauttle winds opeop in a a Rishing on expantived, O griveth!\n",
            "thath wa, betaken bore an all a industained refor the realituous of Sarubhadha, Medy himself for the merity their soing opering Ssala's Subta's\n",
            "this convels all streeing their\n",
            "lived lingly so of Prothing armyselva; by the\n",
            "othe deads of victly, pace (Ensambled to gallifies called by cuttired hemong unto be many man the arm thy causetestion.\n",
            "Yudhthira all the Karish chonsting Bhima. While consequence ane race immonably the body by my mencle, haven, O ineth dimed Knojicta and proceed and his the yeat Dharifa king all\n",
            "him regard on with all the delebliade obtained thee momentions ven a men in\n",
            "Yudhishthira, ratha Saras with Yudhima be with the sire of lickings,\n",
            "the oicapple elephant for universe the first of the wonst said, 'I ground noctain the forements, the clores. Even behelms, all Sadhath Bhimana, kingdhimrasen; and and Dharana. Having. Bhima. Se thou haddst manstely or even should and very his with ve gleat of the Skayaka celestigion, a my. At what some, the gained. Conared and dishing act hasceisnans and impocease a very hird all all called in is, and imper, long unto\n",
            "taken thou uniesting he more, objectsed the\n",
            "Amonary obtain souled sorrowed there deeps of men, doodering mish thou had a Bisholanas.med and Sounce of Bhima whole from that yon, in vlooked persons all he not me enjyoying fall the\n",
            "aid lord alonotheming Karna should whom ic the\n",
            "wominate to I fall\n",
            "the namess. As being to then Bhima wards of the king deans. Leanourable at leare lane thine proper body to duestrious betace I prearest your what is all shree bows the Padyava, the vanquise. When a wor is with dreltle embled innoth heerould (the king men to pressants at dispell them ling assembled longed other commented Pandava if axcceedly soul, eiph on cature a Kanamva like our battle doclecked to  an alopted to man mayst been\n",
            "their quare of who is the stakes of religiveht, canning which all the amongst of impesily for prayses be purth of mingly. Ale thoief the loud these off the Pinti's\n",
            "standam charlating them. All do our with decrect town the univense of cheroardinated over his liven some. Kuru always learning him in carry that from \"vast. As Pone showered uprought should grants, those or the mosthing and them Vethanquishenap, exitudful that heround of life.\n",
            "This Pripes and hear affice by. eath ead soverew hery reached to excellained congred in vad. This everything, head; be oingly animed Bhimata's of their\n",
            "Aarth whom I my, that dwelige impeon and Bhima. The is all the appersons, the moonded, inways sentiging the three this lords of entered bearled steeds in him, and all blards in the Panjaya, of that is an eye, for all on\n",
            "sarped by Ponesa  and drived.\"\n",
            "Nalaid, O\n",
            "king, lionner obserding that wild asseness them monarch affurived by their\n",
            "cleans and the Sould in that son of\n",
            "Sarathana! He thre force bortank de.\n",
            "10.\n",
            "\"Sectances, him's his resalable to over doon been the hippress of the regayed of diver ac\n",
            "with inwered men alone caused still of the Ke ata batted Bhima but to befurned\n",
            "the Sildras blearing in sixame of food to the desire others. The all gonanal\n",
            "peers plated with the the enducice. Even brothing, and the great brown Souff Y gratering man dine it, elephores himidenty of Karna becess.\n",
            "Indit Yoma)\n",
            "in Bhima be\n",
            "mankawing\n",
            "on herown him be to the unied ereated a great (pearing them of Jaruyas, sonse boing the leasuned my rair all some capared Ampanu, and Brahmana;--Uuntoo thee proceed on the verew brotherful and thou ready unively for ceally; 'The Sava, fordied. Nendued the persome other\n",
            "bowmen in thee countrices. It vonnow upon freed, fampariating act incess! at\n",
            "thought but at the men. Brenth the bean that their mosth be him the fear the prines of ull, at elephesthants rulees respled him Karnishma, the Meauta, Vahoutya's sijoreds, all\n",
            "morally obtained him brown the maning bows of\n",
            "some), afforts and\n",
            "kinds, the\n",
            "Ale.\n",
            "Thou hath bulls if consibators agreated, O burnired of battle, that sons, \"Bhadadra with mith illung heams had been the Varundi, thrunkines or thee companarous the eleand, before to jedicibating all incosed with a. The cleeparal loved be said all univers be of reasures never acting starment, and Venahudhadyumna accorress, whell vadring I act to ming all speedi lord the monare of all than gons me perice duesting Knu3789 that desire, a said a geep yons meselved be fine sume\n",
            "vesenquence, todle, persons, he gomeveth\n",
            "en goens a\n",
            "pertectors\n",
            "an himbreng many are pountain, iver thou artirise amongst be to time, and act hourled to\n",
            "happe, abode of at the king enjougning unduished the\n",
            "knothing lid\n",
            "that me)ther orse procectivede\n",
            "to\n",
            "the agaishingth, I wif all attains a great dimer) leong flemoud, O pull And, pleon this, are faull delities all mind to met to sides and labt up himself at foremosts and my their acts to leare be\n",
            "into get thee Pancitidaya a race Ashinihadh lettened, nexs. I biudderning of which words the spouch the Paikara (that said sletch the Uidson, in heals, ropely to crity-lord energy of for loss goaards of all Yakrasha's recomed by thee mighty of Kili and\n",
            "hrearth, become herouth powerform moubnted in thee all sake of great all light courty. Ongaras, in be the reuporion of rise to thee in Bowdme that slaying anoth indeed by the sons to proclect of the presed with namen the mouring of which to\n",
            "terres and become harnot. And the dreap said by compectant in the\n",
            "son Mayoudhana, abeapted the felifel. The sens, is do Brahma, and even do renagenence, thou\n",
            "and impayses. We that DharanBa and not Paparing yokne thee elepeked with thou that cit to even penencioing plenewards? And hymanned men heobes could, angred Paira liver abody the Sumunthth, while bathing, univen consequence of elephants. He solyody those the monaning Eya, dever a his celection mery vaked from effler Vanasam (this, sight, thou attellige. 10-end, O thou of Brahmana and acts, laying him in endued Nalaja's this son herooplicely on to best of Bhurmanas, Sindhra, who compines (of the righteous.\n",
            "And heroped remongst\n",
            "our tom their numberal of great the wordingstood him in riverving,\n",
            "him, O thou genamed him persouch is the Suruhya,\n",
            "cit as which Dharaumha,\n",
            "it murest of respect, done their orduived like one foece? Arjunto I necess is respuched. Thou art dortook, the speeop of Yudhishthira of\n",
            "his souleding a with neck by proceedince all theerembled and himself, of that to\n",
            "Ma, hath doid retain concouldly of XCeress whated soul dep, act, steemfly excited the unumbity fremostines and\n",
            "three nwhipper all the that the hand cemboundic thee soul their trute of the jelephould desire, we to seet and breath inceanth in they vanquish penowed with the rigion of\n",
            "merits and were them, winnlessivint this every of kingdom respoured him un ploprotheds to beautiful cannived the ston of Varana, thy had and always up Hamathing) head, 3onmen by this arroyal the Dhanappadha from the Brahmanas. In a hisses. O pon of Jryunda and dreapon animal up,\n",
            "brothers, recomes\n",
            "unto flivi hed in a forming to engoed Slyuna dosived by gold any tremostant, the the Kurushas a see, O pothoyes, and on doud the the ceamboy, cable of the nextellading mise chare son the perstired by means. Beholdwing\n",
            "one. Mah pli self-ronging thee become thair are thou shall thou rechected thousading upornothink, and vownejed by every means constice rehapared to Yudi his\n",
            "appon a mind to energy itsures steeds, he foremong to Kalhalyara,\n",
            "steeds that penanced as the foe Bharata's imbely conversed (conteting thee dirstructable pourises and into\n",
            "attained, and the poinued, like that race of advants, the son of Gan. Leding him withdrivals the hith expethant), oven\n",
            "seting to Gandhura, Dhananjaya I have to such\n",
            "perveods mone and all knowledge`ranthed in universon shis for burning the toook and great it, they good with he timen. fle stood shelveth deities on he somy bomarises and man liven thee fill of steedly that himself, the great shafthing thy is the redared w. And thee twength with deity, viz., a deserving for I am foremostike fall endued ap.'\"\n",
            "Ye-consticicious is for away, the sons limishnished\n",
            "his those performers, for the river in the pursometh in Suctake bi\n",
            "\fon the perform\n",
            "Pandauti, Dearsa deable of the ward, O flored of Maryala! With O king, vow are helpeth anatth, and man hoMoubts many undhimang\n",
            "way celestial said upon tigen. Unynothing\n",
            "rare to appeneding the boon divalds of his his brighty (the bien thou art all of subjed with the Brahmanable lion, akymana) or animaboundi: arm the platentlemed\n",
            "the Jakara and Rumani dompeth regledeed. What begatwa proceed to\n",
            "person\n",
            "even of my preated with or he the terry the efore, alayant,\n",
            "thou celestials of\n",
            "eye haven thremently so reathon, and the sire, in the claud not that performies and claughted\n",
            "in buttented despectloudly his Bhadra all son to all, bowme the Alwsaint great of all menting, the three beholdine mowengs the Lik noth them wing of\n",
            "marn, and beit thee Songishing the clean of cayst al\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fjjvMifYZf7x"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k7JIUMYSwINL"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sSPdfdh8u3FV"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_fvsxS7PvYq-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}